{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparam Tuning\n",
    "\n",
    "Now that we know which models are performing better, it's time to perform cross validation and tune hyperparameters.\n",
    "- Do a google search for hyperparameter ranges for each type of model.\n",
    "\n",
    "GridSearch/RandomSearch are a great methods for checking off both of these tasks.\n",
    "\n",
    "There is a fairly significant issue with this approach for this particular problem (described below). But in the interest of creating a basic functional pipeline, you can just use the default Sklearn methods for now.\n",
    "\n",
    "## Preventing Data Leakage in Tuning - STRETCH\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its highly recommended you complete it, if you have time!**\n",
    "\n",
    "BUT we have a problem - if we calculated a numerical value to encode city (such as the mean of sale prices in that city) on the training data, we can't cross validate \n",
    "- The rows in each validation fold were part of the original calculation of the mean for that city - that means we're leaking information!\n",
    "- While sklearn's built in functions are extremely useful, sometimes it is necessary to do things ourselves\n",
    "\n",
    "You need to create two functions to replicate what Gridsearch does under the hood. This is a challenging, real world data problem! To help you out, we've created some psuedocode and docstrings to get you started. \n",
    "\n",
    "**`custom_cross_validation()`**\n",
    "- Should take the training data, and divide it into multiple train/validation splits. \n",
    "- Look into `sklearn.model_selection.KFold` to accomplish this - the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html) shows how to split a dataframe and loop through the indexes of your split data. \n",
    "- Within your function, you should compute the city means on the training folds just like you did in Notebook 1 - you may have to re-join the city column to do this - and then join these values to the validation fold\n",
    "\n",
    "This psuedocode may help you fill in the function:\n",
    "\n",
    "```python\n",
    "kfold = KFold() # fit sklearn k folds on X_train\n",
    "train_folds = []\n",
    "val_folds = []\n",
    "for training_index, val_index in kfold.split(X_train):\n",
    "    train_fold, val_fold = #.iloc loop variables on X_train\n",
    "\n",
    "    # recompute training city means like you did in notebook 1 \n",
    "    # merge to validation fold\n",
    "        \n",
    "    train_folds.append(train_fold)\n",
    "    val_folds.append(val_fold)\n",
    "\n",
    "    return train_folds, val_folds\n",
    "```\n",
    "\n",
    "\n",
    "**`hyperparameter_search()`**\n",
    "- Should take the validation and training splits from your previous function, along with your dictionary of hyperparameter values\n",
    "- For each set of hyperparameter values, fit your chosen model on each set of training folds, and take the average of your chosen scoring metric. [itertools.product()](https://docs.python.org/3/library/itertools.html) will be helpful for looping through all combinations of hyperparameter values\n",
    "- Your function should output the hyperparameter values corresponding the highest average score across all folds. Alternatively, it could also output a model object fit on the full training dataset with these parameters.\n",
    "\n",
    "\n",
    "This psuedocode may help you fill in the function:\n",
    "\n",
    "```python\n",
    "hyperparams = # Generate hyperparam options with itertools\n",
    "hyperparam-scores = []\n",
    "for hyperparam-combo in hyperparams:\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for folds in allmyfolds:\n",
    "        # score fold the fold with the model/ hyperparams\n",
    "        scores.append(score-fold)\n",
    "        \n",
    "    score = scores.mean()\n",
    "    hyperparam-scores.append(score)\n",
    "# After loop, find max of hyperparam-scores. Best params are at same index in `hyperparams` loop iteratble\n",
    "```\n",
    "\n",
    "Docstrings have been provided below to get you started. Once you're done developing your functions, you should move them to `functions_variables.py` to keep your notebook clean \n",
    "\n",
    "Bear in mind that these instructions are just one way to tackle this problem - the inputs and output formats don't need to be exactly as specified here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparam Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_variables import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load scaled data\n",
    "X_train_scaled = pd.read_csv(\"../data/processed/X_train_scaled.csv\")\n",
    "X_test_scaled = pd.read_csv(\"../data/processed/X_test_scaled.csv\")\n",
    "\n",
    "# Load scaled target variables\n",
    "y_train_scaled = pd.read_csv(\"../data/processed/y_train_scaled.csv\").values.flatten()  \n",
    "y_test_scaled = pd.read_csv(\"../data/processed/y_test_scaled.csv\").values.flatten()  \n",
    "\n",
    "# Load the feature scaler\n",
    "scaler_features = joblib.load(\"scaler_features.pkl\")\n",
    "\n",
    "# Load the target scaler\n",
    "scaler_target = joblib.load(\"scaler_target.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_scaled shape: (4511, 22)\n",
      "X_test_scaled shape: (1128, 22)\n",
      "y_train_scaled shape: (4511,)\n",
      "y_test_scaled shape: (1128,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_scaled shape:\", X_train_scaled.shape)\n",
    "print(\"X_test_scaled shape:\", X_test_scaled.shape)\n",
    "print(\"y_train_scaled shape:\", y_train_scaled.shape)\n",
    "print(\"y_test_scaled shape:\", y_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Best Parameters (Linear Regression): {}\n",
      "Best RMSE (Linear Regression): 0.7605343929482624\n",
      "LinearRegression:\n",
      "  Train RMSE: $218105.78, Test RMSE: $224965.86\n",
      "  Train MAE: $139397.52, Test MAE: $144474.05\n",
      "  Train R^2: 0.43, Test R^2: 0.47\n",
      "Train RMSE: 218105.78\n",
      "Test RMSE: 224965.86\n",
      "Train MAE: 139397.52\n",
      "Test MAE: 144474.05\n",
      "Train R^2: 0.43\n",
      "Test R^2: 0.47\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "lr_param_grid = {}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "lr_grid_search = GridSearchCV(\n",
    "    estimator=lr_model,\n",
    "    param_grid=lr_param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "lr_grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "print(\"Best Parameters (Linear Regression):\", lr_grid_search.best_params_)\n",
    "print(\"Best RMSE (Linear Regression):\", -lr_grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the train and test sets\n",
    "best_lr_model = lr_grid_search.best_estimator_\n",
    "results_lr = evaluate_model(best_lr_model, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_target)\n",
    "\n",
    "# Display evaluation results\n",
    "for metric, value in results_lr.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Parameters (Ridge): {'alpha': 1}\n",
      "Best RMSE (Ridge): 0.7605293796400723\n",
      "Ridge:\n",
      "  Train RMSE: $218105.89, Test RMSE: $224962.01\n",
      "  Train MAE: $139386.57, Test MAE: $144454.04\n",
      "  Train R^2: 0.43, Test R^2: 0.47\n",
      "Train RMSE: 218105.89\n",
      "Test RMSE: 224962.01\n",
      "Train MAE: 139386.57\n",
      "Test MAE: 144454.04\n",
      "Train R^2: 0.43\n",
      "Test R^2: 0.47\n"
     ]
    }
   ],
   "source": [
    "#Ridge Regression model\n",
    "ridge_model = Ridge()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "ridge_param_grid = {\n",
    "    'alpha': [0.1, 1, 10, 100]  # Regularization strength\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "ridge_grid_search = GridSearchCV(\n",
    "    estimator=ridge_model,\n",
    "    param_grid=ridge_param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "ridge_grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Best parameters and performance\n",
    "print(\"Best Parameters (Ridge):\", ridge_grid_search.best_params_)\n",
    "print(\"Best RMSE (Ridge):\", -ridge_grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the train and test sets\n",
    "best_ridge_model = ridge_grid_search.best_estimator_\n",
    "results_ridge = evaluate_model(best_ridge_model, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_target)\n",
    "\n",
    "# Display evaluation results\n",
    "for metric, value in results_ridge.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best Parameters (SVR): {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best RMSE (SVR): 0.28412505156944706\n",
      "SVR:\n",
      "  Train RMSE: $54612.45, Test RMSE: $75196.92\n",
      "  Train MAE: $31221.08, Test MAE: $37356.25\n",
      "  Train R^2: 0.96, Test R^2: 0.94\n",
      "Train RMSE: 54612.45\n",
      "Test RMSE: 75196.92\n",
      "Train MAE: 31221.08\n",
      "Test MAE: 37356.25\n",
      "Train R^2: 0.96\n",
      "Test R^2: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Define the SVR model\n",
    "svr_model = SVR()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "svr_param_grid = {\n",
    "    'kernel': ['rbf'],  \n",
    "    'C': [0.1, 1, 10],  \n",
    "    'gamma': ['scale', 'auto']  \n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "svr_grid_search = GridSearchCV(\n",
    "    estimator=svr_model,\n",
    "    param_grid=svr_param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "svr_grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Best parameters and performance\n",
    "print(\"Best Parameters (SVR):\", svr_grid_search.best_params_)\n",
    "print(\"Best RMSE (SVR):\", -svr_grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the train and test sets\n",
    "best_svr_model = svr_grid_search.best_estimator_\n",
    "results_svr = evaluate_model(best_svr_model, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_target)\n",
    "\n",
    "# Display evaluation results\n",
    "for metric, value in results_svr.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting GridSearchCV for Random Forest...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "\n",
      "Best Parameters (Random Forest): {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Best RMSE (Random Forest): 0.16489315812457042\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch for Random Forest\n",
    "\n",
    "rf_grid_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV for Random Forest\n",
    "best_rf_grid_model = GridSearchCV(\n",
    "    estimator=rf_grid_model,\n",
    "    param_grid=rf_param_grid,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV for Random Forest\n",
    "print(\"Fitting GridSearchCV for Random Forest...\")\n",
    "best_rf_grid_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Output best parameters and performance\n",
    "print(\"\\nBest Parameters (Random Forest):\", best_rf_grid_model.best_params_)\n",
    "print(\"Best RMSE (Random Forest):\", -best_rf_grid_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor:\n",
      "  Train RMSE: $13682.07, Test RMSE: $29029.00\n",
      "  Train MAE: $4512.14, Test MAE: $9801.14\n",
      "  Train R^2: 1.00, Test R^2: 0.99\n",
      "\n",
      "Random Forest Results on Train/Test Set:\n",
      "Train RMSE: 13682.07\n",
      "Test RMSE: 29029.00\n",
      "Train MAE: 4512.14\n",
      "Test MAE: 9801.14\n",
      "Train R^2: 1.00\n",
      "Test R^2: 0.99\n"
     ]
    }
   ],
   "source": [
    "best_rf_grid_model = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    "    max_depth=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the Random Forest model\n",
    "best_rf_grid_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_results = evaluate_model(best_rf_grid_model, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_target)\n",
    "print(\"\\nRandom Forest Results on Train/Test Set:\")\n",
    "for metric, value in rf_results.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Parameters (Random Forest): {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': None}\n",
      "Best RMSE (Random Forest): 0.16358682300912028\n"
     ]
    }
   ],
   "source": [
    "# RamdonizedSearch for Random Forest\n",
    "rf_model_random = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': [None, 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV for Random Forest\n",
    "best_rf_random_model = RandomizedSearchCV(\n",
    "    estimator=rf_model_random,\n",
    "    param_distributions=rf_param_grid,\n",
    "    n_iter=50,  # Number of combinations to try\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV for Random Forest\n",
    "best_rf_random_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Output best parameters and performance\n",
    "print(\"Best Parameters (Random Forest):\", best_rf_random_model.best_params_)\n",
    "print(\"Best RMSE (Random Forest):\", -best_rf_random_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor:\n",
      "  Train RMSE: $13682.07, Test RMSE: $29029.00\n",
      "  Train MAE: $4512.14, Test MAE: $9801.14\n",
      "  Train R^2: 1.00, Test R^2: 0.99\n",
      "\n",
      "Random Forest Results on Train/Test Set:\n",
      "Train RMSE: 13682.07\n",
      "Test RMSE: 29029.00\n",
      "Train MAE: 4512.14\n",
      "Test MAE: 9801.14\n",
      "Train R^2: 1.00\n",
      "Test R^2: 0.99\n"
     ]
    }
   ],
   "source": [
    "best_rf_random_model = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='log2',\n",
    "    max_depth=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the Random Forest model\n",
    "best_rf_grid_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_results = evaluate_model(best_rf_grid_model, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_target)\n",
    "print(\"\\nRandom Forest Results on Train/Test Set:\")\n",
    "for metric, value in rf_results.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters (XGBoost): {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.8}\n",
      "Best RMSE (XGBoost): 0.11118157332074514\n"
     ]
    }
   ],
   "source": [
    "#GridSearch for XGBoost\n",
    "\n",
    "xgb_grid_model = XGBRegressor(\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "best_xgb_grid_model = GridSearchCV(\n",
    "    estimator=xgb_grid_model,\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='neg_root_mean_squared_error',  # Minimize RMSE\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the grid search\n",
    "best_xgb_grid_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Best parameters and performance\n",
    "print(\"Best Parameters (XGBoost):\", best_xgb_grid_model.best_params_)\n",
    "print(\"Best RMSE (XGBoost):\", -best_xgb_grid_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor:\n",
      "  Train RMSE: $4120.04, Test RMSE: $22078.77\n",
      "  Train MAE: $2600.69, Test MAE: $5328.10\n",
      "  Train R^2: 1.00, Test R^2: 0.99\n",
      "Train RMSE: 4120.04\n",
      "Test RMSE: 22078.77\n",
      "Train MAE: 2600.69\n",
      "Test MAE: 5328.10\n",
      "Train R^2: 1.00\n",
      "Test R^2: 0.99\n"
     ]
    }
   ],
   "source": [
    "best_xgb_grid_model = XGBRegressor(\n",
    "    subsample=0.8,\n",
    "    n_estimators=300,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.1,\n",
    "    gamma=0,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "\n",
    "best_xgb_grid_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Evaluate the model on the train and test sets\n",
    "results_xgb = evaluate_model(best_xgb_grid_model, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_target)\n",
    "\n",
    "# Display evaluation results\n",
    "for metric, value in results_xgb.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best Parameters (XGBoost): {'subsample': 1.0, 'n_estimators': 200, 'max_depth': 7, 'learning_rate': 0.2, 'gamma': 0, 'colsample_bytree': 0.6}\n",
      "Best RMSE (XGBoost): 0.10630633999453828\n"
     ]
    }
   ],
   "source": [
    "#RandomizedSearchCV for XGBoost\n",
    "\n",
    "xgb_random_model = XGBRegressor(random_state=42, objective='reg:squarederror')\n",
    "\n",
    "# Define the parameter grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 5],\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV for XGBoost\n",
    "best_xgb_random_model = RandomizedSearchCV(\n",
    "    estimator=xgb_random_model,\n",
    "    param_distributions=xgb_param_grid,\n",
    "    n_iter=50,  # Number of combinations to try\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit RandomizedSearchCV for XGBoost\n",
    "best_xgb_random_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Output best parameters and performance\n",
    "print(\"Best Parameters (XGBoost):\", best_xgb_random_model.best_params_)\n",
    "print(\"Best RMSE (XGBoost):\", -best_xgb_random_model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor:\n",
      "  Train RMSE: $3444.88, Test RMSE: $24228.19\n",
      "  Train MAE: $2079.72, Test MAE: $4794.03\n",
      "  Train R^2: 1.00, Test R^2: 0.99\n",
      "Train RMSE: 3444.88\n",
      "Test RMSE: 24228.19\n",
      "Train MAE: 2079.72\n",
      "Test MAE: 4794.03\n",
      "Train R^2: 1.00\n",
      "Test R^2: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Train the best XGBoost model\n",
    "\n",
    "best_xgb_random_model = XGBRegressor(\n",
    "    subsample=1.0,\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.2,\n",
    "    gamma=0,\n",
    "    colsample_bytree=0.6,\n",
    "    random_state=42,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "\n",
    "best_xgb_random_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Evaluate the model on the train and test sets\n",
    "results_xgb = evaluate_model(best_xgb_random_model, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_target)\n",
    "\n",
    "# Display evaluation results\n",
    "for metric, value in results_xgb.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingRegressor:\n",
      "  Train RMSE: $3486.38, Test RMSE: $24254.97\n",
      "  Train MAE: $2214.41, Test MAE: $4858.01\n",
      "  Train R^2: 1.00, Test R^2: 0.99\n",
      "\n",
      "Stacking Model Results on Test Set:\n",
      "Train RMSE: 3486.38\n",
      "Test RMSE: 24254.97\n",
      "Train MAE: 2214.41\n",
      "Test MAE: 4858.01\n",
      "Train R^2: 1.00\n",
      "Test R^2: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Stacking Regressor for Random Forest and XGBoost\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "base_models = [\n",
    "    ('Random Forest', best_rf_random_model),\n",
    "    ('XGBoost', best_xgb_random_model)\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Create the Stacking Regressor\n",
    "stacked_model = StackingRegressor(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the Stacking Regressor\n",
    "stacked_model.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Evaluate the Stacking Regressor\n",
    "stacking_results = evaluate_model(stacked_model, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_target)\n",
    "print(\"\\nStacking Model Results on Test Set:\")\n",
    "for metric, value in stacking_results.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE: 0.11\n"
     ]
    }
   ],
   "source": [
    "# cross-validation\n",
    "cv_scores = cross_val_score(\n",
    "    estimator=stacked_model,\n",
    "    X=X_train_scaled,\n",
    "    y=y_train_scaled,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "cv_rmse = -cv_scores.mean()\n",
    "print(f\"Cross-Validation RMSE: {cv_rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing cross-validation for Linear Regression...\n",
      "Linear Regression Mean RMSE: 0.76\n",
      "Performing cross-validation for Ridge Regression...\n",
      "Ridge Regression Mean RMSE: 0.76\n",
      "Performing cross-validation for Polynomial Regression (Linear)...\n",
      "Polynomial Regression (Linear) Mean RMSE: 0.76\n",
      "Performing cross-validation for Polynomial Regression (Ridge)...\n",
      "Polynomial Regression (Ridge) Mean RMSE: 0.76\n",
      "Performing cross-validation for SVR...\n",
      "SVR Mean RMSE: 0.53\n",
      "Performing cross-validation for Random Forest...\n",
      "Random Forest Mean RMSE: 0.18\n",
      "Performing cross-validation for XGBoost...\n",
      "XGBoost Mean RMSE: 0.12\n",
      "\n",
      "Model: Linear Regression\n",
      "Per-Fold RMSE: [0.80507954 0.78157251 0.7834044  0.69273471 0.73988079]\n",
      "Mean RMSE: 0.76\n",
      "\n",
      "Model: Ridge Regression\n",
      "Per-Fold RMSE: [0.80502612 0.78162051 0.78342169 0.69273827 0.7398403 ]\n",
      "Mean RMSE: 0.76\n",
      "\n",
      "Model: Polynomial Regression (Linear)\n",
      "Per-Fold RMSE: [0.80507954 0.78157251 0.7834044  0.69273471 0.73988079]\n",
      "Mean RMSE: 0.76\n",
      "\n",
      "Model: Polynomial Regression (Ridge)\n",
      "Per-Fold RMSE: [0.80502612 0.78162051 0.78342169 0.69273827 0.7398403 ]\n",
      "Mean RMSE: 0.76\n",
      "\n",
      "Model: SVR\n",
      "Per-Fold RMSE: [0.59163877 0.55984113 0.58558292 0.44635951 0.48875452]\n",
      "Mean RMSE: 0.53\n",
      "\n",
      "Model: Random Forest\n",
      "Per-Fold RMSE: [0.22999197 0.17667992 0.15678455 0.17075181 0.18219775]\n",
      "Mean RMSE: 0.18\n",
      "\n",
      "Model: XGBoost\n",
      "Per-Fold RMSE: [0.17650851 0.11034959 0.13738552 0.07167766 0.12077853]\n",
      "Mean RMSE: 0.12\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation\n",
    "models = {\n",
    "    \"Linear Regression\": lr_model,\n",
    "    \"Ridge Regression\": ridge_model,\n",
    "    \"Polynomial Regression (Linear)\": lr_model,\n",
    "    \"Polynomial Regression (Ridge)\": ridge_model,\n",
    "    \"SVR\": SVR(kernel='rbf', C=1.0, gamma='scale'),  \n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=300, random_state=42), \n",
    "    \"XGBoost\": XGBRegressor(n_estimators=300, max_depth=7, learning_rate=0.1, random_state=42)\n",
    "}\n",
    "\n",
    "cv_results = perform_cross_validation(\n",
    "    models=models,\n",
    "    X=X_train_scaled,   \n",
    "    y=y_train_scaled,   \n",
    "    cv=5                \n",
    ")\n",
    "\n",
    "for model_name, result in cv_results.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(f\"Per-Fold RMSE: {result['Per-Fold RMSE']}\")\n",
    "    print(f\"Mean RMSE: {result['Mean RMSE']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make sure that we save our models.  In the old days, one just simply pickled (serialized) the model.  Now, however, certain model types have their own save format.  If the model is from sklearn, it can be pickled, if it's xgboost, for example, the newest format to save it in is JSON, but it can also be pickled.  It's a good idea to stay with the most current methods. \n",
    "- you may want to create a new `models/` subdirectory in your repo to stay organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stacked_model.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Save the trained stacking model to a file\n",
    "dump(stacked_model, 'stacked_model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Pipeline (Stretch)\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its highly recommended you complete it if you have time!**\n",
    "\n",
    "Once you've identified which model works the best, implement a prediction pipeline to make sure that you haven't leaked any data, and that the model could be easily deployed if desired.\n",
    "- Your pipeline should load the data, process it, load your saved tuned model, and output a set of predictions\n",
    "- Assume that the new data is in the same JSON format as your original data - you can use your original data to check that the pipeline works correctly\n",
    "- Beware that a pipeline can only handle functions with fit and transform methods.\n",
    "- Classes can be used to get around this, but now sklearn has a wrapper for user defined functions.\n",
    "- You can develop your functions or classes in the notebook here, but once they are working, you should import them from `functions_variables.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pipeline here\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import load\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Custom Transformer for Feature Selection\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.features]\n",
    "\n",
    "# Custom Transformer for JSON to DataFrame conversion\n",
    "class JSONLoader(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_columns):\n",
    "        self.feature_columns = feature_columns\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, json_file_path):\n",
    "        with open(json_file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        # Flatten the JSON and convert to DataFrame\n",
    "        results = data.get('data', {}).get('results', [])\n",
    "        df = pd.json_normalize(results)\n",
    "        \n",
    "        # Select only the necessary columns\n",
    "        df = df[self.feature_columns]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to be used for prediction (based on feature selection)\n",
    "selected_features = [\n",
    "    'description_baths', 'description_beds', 'description_sqft', \n",
    "    'community_security_features', 'fireplace', 'view'\n",
    "]\n",
    "\n",
    "# Load the saved model\n",
    "stacked_model_path = 'stacked_model.pkl'\n",
    "stacked_model = load(stacked_model_path)\n",
    "\n",
    "# Create the pipeline\n",
    "prediction_pipeline = Pipeline([\n",
    "    ('json_loader', JSONLoader(feature_columns=selected_features)),\n",
    "    ('scaler', StandardScaler()),  # Ensure consistent scaling\n",
    "        ('model', stacked_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Steps: [('json_loader', JSONLoader(feature_columns=['description_baths', 'description_beds',\n",
      "                            'description_sqft', 'community_security_features',\n",
      "                            'fireplace', 'view'])), ('scaler', StandardScaler()), ('model', StackingRegressor(cv=5,\n",
      "                  estimators=[('Random Forest',\n",
      "                               RandomForestRegressor(max_features='log2',\n",
      "                                                     n_estimators=500,\n",
      "                                                     random_state=42)),\n",
      "                              ('XGBoost',\n",
      "                               XGBRegressor(base_score=None, booster=None,\n",
      "                                            callbacks=None,\n",
      "                                            colsample_bylevel=None,\n",
      "                                            colsample_bynode=None,\n",
      "                                            colsample_bytree=0.6, device=None,\n",
      "                                            early_stopping_rounds=None,\n",
      "                                            enable_categorical=False,\n",
      "                                            eval_metric=None,\n",
      "                                            feature...\n",
      "                                            interaction_constraints=None,\n",
      "                                            learning_rate=0.2, max_bin=None,\n",
      "                                            max_cat_threshold=None,\n",
      "                                            max_cat_to_onehot=None,\n",
      "                                            max_delta_step=None, max_depth=7,\n",
      "                                            max_leaves=None,\n",
      "                                            min_child_weight=None, missing=nan,\n",
      "                                            monotone_constraints=None,\n",
      "                                            multi_strategy=None,\n",
      "                                            n_estimators=200, n_jobs=None,\n",
      "                                            num_parallel_tree=None,\n",
      "                                            random_state=42, ...))],\n",
      "                  final_estimator=LinearRegression(), n_jobs=-1))]\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m     prediction_pipeline\u001b[38;5;241m.\u001b[39msteps\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Predict with the pipeline\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m new_data_predictions \u001b[38;5;241m=\u001b[39m prediction_pipeline\u001b[38;5;241m.\u001b[39mpredict(feature_matrix)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions on new data:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_data_predictions)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/pipeline.py:600\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[1;32m    599\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/preprocessing/_data.py:1042\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Perform standardization by centering and scaling.\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \n\u001b[1;32m   1030\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;124;03m        Transformed array.\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1042\u001b[0m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1044\u001b[0m     copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m   1045\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m   1046\u001b[0m         X,\n\u001b[1;32m   1047\u001b[0m         reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1052\u001b[0m         force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1053\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:1661\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# Path to the new JSON data\n",
    "new_json_data_path = '/home/t0si/Documents/LHL-Midterm-Project/data/housing/MO_JeffersonCity_3.json'\n",
    "\n",
    "# Load the JSON data\n",
    "with open(new_json_data_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Flatten the JSON and convert to DataFrame\n",
    "results = data.get('data', {}).get('results', [])\n",
    "df = pd.json_normalize(results)\n",
    "\n",
    "# Extract tags and process features if necessary\n",
    "if 'tags' in df.columns:\n",
    "    df['tags'] = df['tags'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "    features_to_extract = [\n",
    "        'community.securityFeatures',\n",
    "        'description.fireplace',\n",
    "        'description.view'\n",
    "    ]\n",
    "    for feature in features_to_extract:\n",
    "        df[feature] = df['tags'].apply(lambda x: 1 if feature in x else 0)\n",
    "    df = df.drop(columns=['tags'], errors='ignore')\n",
    "\n",
    "# Selected features for the model\n",
    "selected_features = [\n",
    "    'description.baths', 'description.beds', 'description.sqft', \n",
    "    'community.securityFeatures', 'description.fireplace', 'description.view'\n",
    "]\n",
    "\n",
    "# Validate features\n",
    "missing_features = [feature for feature in selected_features if feature not in df.columns]\n",
    "if missing_features:\n",
    "    print(f\"Error: Missing features in the DataFrame: {missing_features}\")\n",
    "else:\n",
    "    # Prepare the feature matrix\n",
    "    feature_matrix = df[selected_features].values\n",
    "\n",
    "    # Load the pipeline\n",
    "    prediction_pipeline = load('prediction_pipeline.pkl')\n",
    "\n",
    "    # Check pipeline steps\n",
    "    print(\"Pipeline Steps:\", prediction_pipeline.steps)\n",
    "\n",
    "    # Remove json_loader step if present\n",
    "    if 'json_loader' in dict(prediction_pipeline.steps):\n",
    "        prediction_pipeline.steps.pop(0)\n",
    "\n",
    "    # Predict with the pipeline\n",
    "    new_data_predictions = prediction_pipeline.predict(feature_matrix)\n",
    "    print(\"Predictions on new data:\")\n",
    "    print(new_data_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines come from sklearn.  When a pipeline is pickled, all of the information in the pipeline is stored with it.  For example, if we were deploying a model, and we had fit a scaler on the training data, we would want the same, already fitted scaling object to transform the new data with.  This is all stored when the pipeline is pickled.\n",
    "- save your final pipeline in your `models/` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your pipeline here# Save the pipeline\n",
    "dump(prediction_pipeline, 'prediction_pipeline.pkl')\n",
    "print(\"Prediction pipeline saved as 'prediction_pipeline.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
