{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "This notebook should include preliminary and baseline modeling.\n",
    "- Try as many different models as possible.\n",
    "- Don't worry about hyperparameter tuning or cross validation here.\n",
    "- Ideas include:\n",
    "    - linear regression\n",
    "    - support vector machines\n",
    "    - random forest\n",
    "    - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import root_mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from functions_variables import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "Y_train = pd.read_csv('../data/processed/Y_train.csv').squeeze()\n",
    "Y_test = pd.read_csv('../data/processed/Y_test.csv').squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4511, 22)\n",
      "X_test shape: (1128, 22)\n",
      "y_train shape: (4511,)\n",
      "y_test shape: (1128,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", Y_train.shape)\n",
    "print(\"y_test shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_features = StandardScaler()\n",
    "\n",
    "columns_to_scale = [\n",
    "    'description_baths', 'description_beds', 'description_garage',\n",
    "    'description_sqft', 'description_stories', 'description_year_built',\n",
    "    'year_sold', 'year_listed', 'days_on_market', 'city_frequency', 'state_frequency'\n",
    "]\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[columns_to_scale] = scaler_features.fit_transform(X_train[columns_to_scale])\n",
    "X_test_scaled[columns_to_scale] = scaler_features.transform(X_test[columns_to_scale])\n",
    "\n",
    "scaler_target = StandardScaler()\n",
    "y_train_scaled = scaler_target.fit_transform(Y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_target.transform(Y_test.values.reshape(-1, 1)).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = '../data/processed/'\n",
    "X_train_scaled.to_csv(processed_data_path + 'X_train_scaled.csv', index=False)\n",
    "X_test_scaled.to_csv(processed_data_path + 'X_test_scaled.csv', index=False)\n",
    "\n",
    "# Save y_train_scaled and y_test_scaled\n",
    "pd.DataFrame(y_train_scaled, columns=[\"y_train_scaled\"]).to_csv(processed_data_path + 'y_train_scaled.csv', index=False)\n",
    "pd.DataFrame(y_test_scaled, columns=[\"y_test_scaled\"]).to_csv(processed_data_path + 'y_test_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Train RMSE: $218220.76, Test RMSE: $225634.32\n",
      "  Train MAE: $139385.10, Test MAE: $145045.50\n",
      "  Train R^2: 0.43, Test R^2: 0.47\n",
      "SVR:\n",
      "  Train RMSE: $129333.31, Test RMSE: $151565.00\n",
      "  Train MAE: $58366.07, Test MAE: $72227.78\n",
      "  Train R^2: 0.80, Test R^2: 0.76\n",
      "RandomForestRegressor:\n",
      "  Train RMSE: $16560.35, Test RMSE: $40315.56\n",
      "  Train MAE: $4951.29, Test MAE: $11727.67\n",
      "  Train R^2: 1.00, Test R^2: 0.98\n",
      "XGBRegressor:\n",
      "  Train RMSE: $12616.08, Test RMSE: $37015.39\n",
      "  Train MAE: $8478.83, Test MAE: $14151.74\n",
      "  Train R^2: 1.00, Test R^2: 0.99\n",
      "\n",
      "Model: Linear Regression\n",
      "  Train RMSE: 218220.76\n",
      "  Test RMSE: 225634.32\n",
      "  Train MAE: 139385.10\n",
      "  Test MAE: 145045.50\n",
      "  Train R^2: 0.43\n",
      "  Test R^2: 0.47\n",
      "\n",
      "Model: SVR\n",
      "  Train RMSE: 129333.31\n",
      "  Test RMSE: 151565.00\n",
      "  Train MAE: 58366.07\n",
      "  Test MAE: 72227.78\n",
      "  Train R^2: 0.80\n",
      "  Test R^2: 0.76\n",
      "\n",
      "Model: Random Forest\n",
      "  Train RMSE: 16560.35\n",
      "  Test RMSE: 40315.56\n",
      "  Train MAE: 4951.29\n",
      "  Test MAE: 11727.67\n",
      "  Train R^2: 1.00\n",
      "  Test R^2: 0.98\n",
      "\n",
      "Model: XGBoost\n",
      "  Train RMSE: 12616.08\n",
      "  Test RMSE: 37015.39\n",
      "  Train MAE: 8478.83\n",
      "  Test MAE: 14151.74\n",
      "  Train R^2: 1.00\n",
      "  Test R^2: 0.99\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'SVR': SVR(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    results[model_name] = evaluate_model(model, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_target)\n",
    "\n",
    "# Display results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        print(f\"  {metric_name}: {metric_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what metrics you want to use to evaluate success.\n",
    "- If you think about mean squared error, can we actually relate to the amount of error?\n",
    "- Try root mean squared error so that error is closer to the original units (dollars)\n",
    "- What does RMSE do to outliers?\n",
    "- Is mean absolute error a good metric for this problem?\n",
    "- What about R^2? Adjusted R^2?\n",
    "- Briefly describe your reasons for picking the metrics you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather evaluation metrics and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - STRETCH\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its recommended you complete it if you have time!**\n",
    "\n",
    "Even with all the preprocessing we did in Notebook 1, you probably still have a lot of features. Are they all important for prediction?\n",
    "\n",
    "Investigate some feature selection algorithms (Lasso, RFE, Forward/Backward Selection)\n",
    "- Perform feature selection to get a reduced subset of your original features\n",
    "- Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?\n",
    "- Based on this, should you include feature selection in your final pipeline? Explain\n",
    "\n",
    "Remember, feature selection often doesn't directly improve performance, but if performance remains the same, a simpler model is often preferrable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (Forward Selection): Index(['description_baths', 'description_sqft', 'community_security_features',\n",
      "       'view', 'city_view'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "base_model = LinearRegression()\n",
    "\n",
    "forward_selector = SequentialFeatureSelector(\n",
    "    estimator=base_model,\n",
    "    n_features_to_select=5,  \n",
    "    direction='forward',  \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "forward_selector.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "selected_features_forward = X_train_scaled.columns[forward_selector.get_support()]\n",
    "print(\"Selected Features (Forward Selection):\", selected_features_forward)\n",
    "\n",
    "X_train_forward = X_train_scaled[selected_features_forward]\n",
    "X_test_forward = X_test_scaled[selected_features_forward]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Train RMSE: $227451.54, Test RMSE: $236042.89\n",
      "  Train MAE: $143682.38, Test MAE: $150038.76\n",
      "  Train R^2: 0.38, Test R^2: 0.42\n",
      "\n",
      "Results with Forward-Selected Features:\n",
      "Train RMSE: 227451.54\n",
      "Test RMSE: 236042.89\n",
      "Train MAE: 143682.38\n",
      "Test MAE: 150038.76\n",
      "Train R^2: 0.38\n",
      "Test R^2: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Linear Regression on forward-selected features\n",
    "lr_model = LinearRegression()\n",
    "results_forward = evaluate_model(lr_model, X_train_forward, X_test_forward, y_train_scaled, y_test_scaled, scaler_target)\n",
    "print(\"\\nResults with Forward-Selected Features:\")\n",
    "for metric, value in results_forward.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (Backward Selection): Index(['description_baths', 'description_sqft', 'community_security_features',\n",
      "       'view', 'city_view'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Perform backward feature selection\n",
    "backward_selector = SequentialFeatureSelector(\n",
    "    estimator=base_model,\n",
    "    n_features_to_select=5,  # Specify the desired number of features\n",
    "    direction='backward',  # Backward selection\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the selector on the training data\n",
    "backward_selector.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features_backward = X_train_scaled.columns[backward_selector.get_support()]\n",
    "print(\"Selected Features (Backward Selection):\", selected_features_backward)\n",
    "\n",
    "# Create new datasets with selected features\n",
    "X_train_backward = X_train_scaled[selected_features_backward]\n",
    "X_test_backward = X_test_scaled[selected_features_backward]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Train RMSE: $227451.54, Test RMSE: $236042.89\n",
      "  Train MAE: $143682.38, Test MAE: $150038.76\n",
      "  Train R^2: 0.38, Test R^2: 0.42\n",
      "\n",
      "Results with Backward-Selected Features:\n",
      "Train RMSE: 227451.54\n",
      "Test RMSE: 236042.89\n",
      "Train MAE: 143682.38\n",
      "Test MAE: 150038.76\n",
      "Train R^2: 0.38\n",
      "Test R^2: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Linear Regression on backward-selected features\n",
    "results_backward = evaluate_model(lr_model, X_train_backward, X_test_backward, y_train_scaled, y_test_scaled, scaler_target)\n",
    "print(\"\\nResults with Backward-Selected Features:\")\n",
    "for metric, value in results_backward.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression with RFE...\n",
      "LinearRegression:\n",
      "  Train RMSE: $218827.46, Test RMSE: $226154.03\n",
      "  Train MAE: $138799.48, Test MAE: $144515.44\n",
      "  Train R^2: 0.43, Test R^2: 0.47\n",
      "Evaluating SVR (Linear Kernel) with RFE...\n",
      "SVR:\n",
      "  Train RMSE: $229750.83, Test RMSE: $240414.21\n",
      "  Train MAE: $129831.58, Test MAE: $137087.51\n",
      "  Train R^2: 0.37, Test R^2: 0.40\n",
      "Evaluating Random Forest with RFE...\n",
      "RandomForestRegressor:\n",
      "  Train RMSE: $16728.11, Test RMSE: $39179.02\n",
      "  Train MAE: $4939.54, Test MAE: $11685.11\n",
      "  Train R^2: 1.00, Test R^2: 0.98\n",
      "Evaluating XGBoost with RFE...\n",
      "XGBRegressor:\n",
      "  Train RMSE: $15590.07, Test RMSE: $28820.07\n",
      "  Train MAE: $10447.51, Test MAE: $14733.02\n",
      "  Train R^2: 1.00, Test R^2: 0.99\n",
      "\n",
      "Model: Linear Regression\n",
      "  Train RMSE: 218827.46\n",
      "  Test RMSE: 226154.03\n",
      "  Train MAE: 138799.48\n",
      "  Test MAE: 144515.44\n",
      "  Train R^2: 0.43\n",
      "  Test R^2: 0.47\n",
      "\n",
      "Model: SVR (Linear Kernel)\n",
      "  Train RMSE: 229750.83\n",
      "  Test RMSE: 240414.21\n",
      "  Train MAE: 129831.58\n",
      "  Test MAE: 137087.51\n",
      "  Train R^2: 0.37\n",
      "  Test R^2: 0.40\n",
      "\n",
      "Model: Random Forest\n",
      "  Train RMSE: 16728.11\n",
      "  Test RMSE: 39179.02\n",
      "  Train MAE: 4939.54\n",
      "  Test MAE: 11685.11\n",
      "  Train R^2: 1.00\n",
      "  Test R^2: 0.98\n",
      "\n",
      "Model: XGBoost\n",
      "  Train RMSE: 15590.07\n",
      "  Test RMSE: 28820.07\n",
      "  Train MAE: 10447.51\n",
      "  Test MAE: 14733.02\n",
      "  Train R^2: 1.00\n",
      "  Test R^2: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Update SVR to use linear kernel\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'SVR (Linear Kernel)': SVR(kernel='linear'),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Loop through each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name} with RFE...\")\n",
    "    \n",
    "    # Apply RFE (skip SVR with non-linear kernel)\n",
    "    try:\n",
    "        rfe = RFE(estimator=model, n_features_to_select=15)  # Adjust the number of features to select\n",
    "        X_train_rfe = rfe.fit_transform(X_train_scaled, y_train_scaled)\n",
    "        X_test_rfe = rfe.transform(X_test_scaled)\n",
    "        \n",
    "        # Evaluate the model with the reduced feature set\n",
    "        results[model_name] = evaluate_model(model, X_train_rfe, X_test_rfe, y_train_scaled, y_test_scaled, scaler_target)\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping RFE for {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Display results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        print(f\"  {metric_name}: {metric_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters (Lasso): {'alpha': 0.001}\n",
      "Best RMSE (Lasso): 0.7609943955509639\n",
      "Lasso:\n",
      "  Train RMSE: $218240.62, Test RMSE: $225650.17\n",
      "  Train MAE: $139107.88, Test MAE: $144784.54\n",
      "  Train R^2: 0.43, Test R^2: 0.47\n",
      "Train RMSE: 218240.62\n",
      "Test RMSE: 225650.17\n",
      "Train MAE: 139107.88\n",
      "Test MAE: 144784.54\n",
      "Train R^2: 0.43\n",
      "Test R^2: 0.47\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "# Define the Lasso Regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "lasso_param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10]  # Regularization strength\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "lasso_grid_search = GridSearchCV(\n",
    "    estimator=lasso_model,\n",
    "    param_grid=lasso_param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "lasso_grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Best parameters and performance\n",
    "print(\"Best Parameters (Lasso):\", lasso_grid_search.best_params_)\n",
    "print(\"Best RMSE (Lasso):\", -lasso_grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the train and test sets\n",
    "best_lasso_model = lasso_grid_search.best_estimator_\n",
    "results_lasso = evaluate_model(best_lasso_model, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_target)\n",
    "\n",
    "# Display evaluation results\n",
    "for metric, value in results_lasso.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather evaluation metrics and compare to the previous step (full feature set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
