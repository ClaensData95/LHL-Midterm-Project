{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "This notebook should include preliminary and baseline modeling.\n",
    "- Try as many different models as possible.\n",
    "- Don't worry about hyperparameter tuning or cross validation here.\n",
    "- Ideas include:\n",
    "    - linear regression\n",
    "    - support vector machines\n",
    "    - random forest\n",
    "    - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_variables import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "Y_train = pd.read_csv('../data/processed/Y_train.csv').squeeze()\n",
    "Y_test = pd.read_csv('../data/processed/Y_test.csv').squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4511, 22)\n",
      "X_test shape: (1128, 22)\n",
      "y_train shape: (4511,)\n",
      "y_test shape: (1128,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", Y_train.shape)\n",
    "print(\"y_test shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_features = StandardScaler()\n",
    "\n",
    "columns_to_scale = [\n",
    "    'description_baths', 'description_beds', 'description_garage',\n",
    "    'description_sqft', 'description_stories', 'description_year_built',\n",
    "    'year_sold', 'year_listed', 'days_on_market', 'city_frequency', 'state_frequency'\n",
    "]\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[columns_to_scale] = scaler_features.fit_transform(X_train[columns_to_scale])\n",
    "X_test_scaled[columns_to_scale] = scaler_features.transform(X_test[columns_to_scale])\n",
    "\n",
    "scaler_target = StandardScaler()\n",
    "y_train_scaled = scaler_target.fit_transform(Y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_target.transform(Y_test.values.reshape(-1, 1)).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = '../data/processed/'\n",
    "X_train_scaled.to_csv(processed_data_path + 'X_train_scaled.csv', index=False)\n",
    "X_test_scaled.to_csv(processed_data_path + 'X_test_scaled.csv', index=False)\n",
    "\n",
    "# Save y_train_scaled and y_test_scaled\n",
    "pd.DataFrame(y_train_scaled, columns=[\"y_train_scaled\"]).to_csv(processed_data_path + 'y_train_scaled.csv', index=False)\n",
    "pd.DataFrame(y_test_scaled, columns=[\"y_test_scaled\"]).to_csv(processed_data_path + 'y_test_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Train RMSE: $218105.78, Test RMSE: $224965.86\n",
      "  Train MAE: $139397.52, Test MAE: $144474.05\n",
      "  Train R^2: 0.43, Test R^2: 0.47\n",
      "SVR:\n",
      "  Train RMSE: $129891.96, Test RMSE: $151913.37\n",
      "  Train MAE: $58657.72, Test MAE: $71472.32\n",
      "  Train R^2: 0.80, Test R^2: 0.76\n",
      "RandomForestRegressor:\n",
      "  Train RMSE: $16426.91, Test RMSE: $31961.82\n",
      "  Train MAE: $4956.85, Test MAE: $11125.30\n",
      "  Train R^2: 1.00, Test R^2: 0.99\n",
      "XGBRegressor:\n",
      "  Train RMSE: $12199.98, Test RMSE: $25978.07\n",
      "  Train MAE: $8332.34, Test MAE: $12242.71\n",
      "  Train R^2: 1.00, Test R^2: 0.99\n",
      "\n",
      "Model: Linear Regression\n",
      "  Train RMSE: 218105.78\n",
      "  Test RMSE: 224965.86\n",
      "  Train MAE: 139397.52\n",
      "  Test MAE: 144474.05\n",
      "  Train R^2: 0.43\n",
      "  Test R^2: 0.47\n",
      "\n",
      "Model: SVR\n",
      "  Train RMSE: 129891.96\n",
      "  Test RMSE: 151913.37\n",
      "  Train MAE: 58657.72\n",
      "  Test MAE: 71472.32\n",
      "  Train R^2: 0.80\n",
      "  Test R^2: 0.76\n",
      "\n",
      "Model: Random Forest\n",
      "  Train RMSE: 16426.91\n",
      "  Test RMSE: 31961.82\n",
      "  Train MAE: 4956.85\n",
      "  Test MAE: 11125.30\n",
      "  Train R^2: 1.00\n",
      "  Test R^2: 0.99\n",
      "\n",
      "Model: XGBoost\n",
      "  Train RMSE: 12199.98\n",
      "  Test RMSE: 25978.07\n",
      "  Train MAE: 8332.34\n",
      "  Test MAE: 12242.71\n",
      "  Train R^2: 1.00\n",
      "  Test R^2: 0.99\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'SVR': SVR(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    results[model_name] = evaluate_model(model, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_target)\n",
    "\n",
    "# Display results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        print(f\"  {metric_name}: {metric_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what metrics you want to use to evaluate success.\n",
    "- If you think about mean squared error, can we actually relate to the amount of error?\n",
    "- Try root mean squared error so that error is closer to the original units (dollars)\n",
    "- What does RMSE do to outliers?\n",
    "- Is mean absolute error a good metric for this problem?\n",
    "- What about R^2? Adjusted R^2?\n",
    "- Briefly describe your reasons for picking the metrics you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather evaluation metrics and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - STRETCH\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its recommended you complete it if you have time!**\n",
    "\n",
    "Even with all the preprocessing we did in Notebook 1, you probably still have a lot of features. Are they all important for prediction?\n",
    "\n",
    "Investigate some feature selection algorithms (Lasso, RFE, Forward/Backward Selection)\n",
    "- Perform feature selection to get a reduced subset of your original features\n",
    "- Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?\n",
    "- Based on this, should you include feature selection in your final pipeline? Explain\n",
    "\n",
    "Remember, feature selection often doesn't directly improve performance, but if performance remains the same, a simpler model is often preferrable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (Forward Selection): Index(['description_baths', 'description_sqft', 'community_security_features',\n",
      "       'view', 'city_view'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "base_model = LinearRegression()\n",
    "\n",
    "forward_selector = SequentialFeatureSelector(\n",
    "    estimator=base_model,\n",
    "    n_features_to_select=5,  \n",
    "    direction='forward',  \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "forward_selector.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "selected_features_forward = X_train_scaled.columns[forward_selector.get_support()]\n",
    "print(\"Selected Features (Forward Selection):\", selected_features_forward)\n",
    "\n",
    "X_train_forward = X_train_scaled[selected_features_forward]\n",
    "X_test_forward = X_test_scaled[selected_features_forward]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Train RMSE: $227407.12, Test RMSE: $235618.29\n",
      "  Train MAE: $143648.98, Test MAE: $149623.41\n",
      "  Train R^2: 0.38, Test R^2: 0.42\n",
      "\n",
      "Results with Forward-Selected Features:\n",
      "Train RMSE: 227407.12\n",
      "Test RMSE: 235618.29\n",
      "Train MAE: 143648.98\n",
      "Test MAE: 149623.41\n",
      "Train R^2: 0.38\n",
      "Test R^2: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Linear Regression on forward-selected features\n",
    "lr_model = LinearRegression()\n",
    "results_forward = evaluate_model(lr_model, X_train_forward, X_test_forward, y_train_scaled, y_test_scaled, scaler_target)\n",
    "print(\"\\nResults with Forward-Selected Features:\")\n",
    "for metric, value in results_forward.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (Backward Selection): Index(['description_baths', 'description_sqft', 'community_security_features',\n",
      "       'view', 'city_view'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Perform backward feature selection\n",
    "backward_selector = SequentialFeatureSelector(\n",
    "    estimator=base_model,\n",
    "    n_features_to_select=5,  # Specify the desired number of features\n",
    "    direction='backward',  # Backward selection\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the selector on the training data\n",
    "backward_selector.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features_backward = X_train_scaled.columns[backward_selector.get_support()]\n",
    "print(\"Selected Features (Backward Selection):\", selected_features_backward)\n",
    "\n",
    "# Create new datasets with selected features\n",
    "X_train_backward = X_train_scaled[selected_features_backward]\n",
    "X_test_backward = X_test_scaled[selected_features_backward]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Train RMSE: $227407.12, Test RMSE: $235618.29\n",
      "  Train MAE: $143648.98, Test MAE: $149623.41\n",
      "  Train R^2: 0.38, Test R^2: 0.42\n",
      "\n",
      "Results with Backward-Selected Features:\n",
      "Train RMSE: 227407.12\n",
      "Test RMSE: 235618.29\n",
      "Train MAE: 143648.98\n",
      "Test MAE: 149623.41\n",
      "Train R^2: 0.38\n",
      "Test R^2: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Linear Regression on backward-selected features\n",
    "results_backward = evaluate_model(lr_model, X_train_backward, X_test_backward, y_train_scaled, y_test_scaled, scaler_target)\n",
    "print(\"\\nResults with Backward-Selected Features:\")\n",
    "for metric, value in results_backward.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression with RFE...\n",
      "LinearRegression:\n",
      "  Train RMSE: $228864.27, Test RMSE: $239980.37\n",
      "  Train MAE: $142403.77, Test MAE: $151402.69\n",
      "  Train R^2: 0.37, Test R^2: 0.40\n",
      "Evaluating SVR (Linear Kernel) with RFE...\n",
      "SVR:\n",
      "  Train RMSE: $234709.85, Test RMSE: $247980.11\n",
      "  Train MAE: $136816.03, Test MAE: $146743.19\n",
      "  Train R^2: 0.34, Test R^2: 0.36\n",
      "Evaluating Random Forest with RFE...\n",
      "RandomForestRegressor:\n",
      "  Train RMSE: $13885.41, Test RMSE: $28044.96\n",
      "  Train MAE: $4359.68, Test MAE: $9821.09\n",
      "  Train R^2: 1.00, Test R^2: 0.99\n",
      "Evaluating XGBoost with RFE...\n",
      "XGBRegressor:\n",
      "  Train RMSE: $35323.18, Test RMSE: $49140.55\n",
      "  Train MAE: $22387.46, Test MAE: $28706.89\n",
      "  Train R^2: 0.99, Test R^2: 0.97\n",
      "\n",
      "Model: Linear Regression\n",
      "  Train RMSE: 228864.27\n",
      "  Test RMSE: 239980.37\n",
      "  Train MAE: 142403.77\n",
      "  Test MAE: 151402.69\n",
      "  Train R^2: 0.37\n",
      "  Test R^2: 0.40\n",
      "\n",
      "Model: SVR (Linear Kernel)\n",
      "  Train RMSE: 234709.85\n",
      "  Test RMSE: 247980.11\n",
      "  Train MAE: 136816.03\n",
      "  Test MAE: 146743.19\n",
      "  Train R^2: 0.34\n",
      "  Test R^2: 0.36\n",
      "\n",
      "Model: Random Forest\n",
      "  Train RMSE: 13885.41\n",
      "  Test RMSE: 28044.96\n",
      "  Train MAE: 4359.68\n",
      "  Test MAE: 9821.09\n",
      "  Train R^2: 1.00\n",
      "  Test R^2: 0.99\n",
      "\n",
      "Model: XGBoost\n",
      "  Train RMSE: 35323.18\n",
      "  Test RMSE: 49140.55\n",
      "  Train MAE: 22387.46\n",
      "  Test MAE: 28706.89\n",
      "  Train R^2: 0.99\n",
      "  Test R^2: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Update SVR to use linear kernel\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'SVR (Linear Kernel)': SVR(kernel='linear'),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Loop through each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name} with RFE...\")\n",
    "    \n",
    "    # Apply RFE (skip SVR with non-linear kernel)\n",
    "    try:\n",
    "        rfe = RFE(estimator=model, n_features_to_select=5)  # Adjust the number of features to select\n",
    "        X_train_rfe = rfe.fit_transform(X_train_scaled, y_train_scaled)\n",
    "        X_test_rfe = rfe.transform(X_test_scaled)\n",
    "        \n",
    "        # Evaluate the model with the reduced feature set\n",
    "        results[model_name] = evaluate_model(model, X_train_rfe, X_test_rfe, y_train_scaled, y_test_scaled, scaler_target)\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping RFE for {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Display results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        print(f\"  {metric_name}: {metric_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters (Lasso): {'alpha': 0.001}\n",
      "Best RMSE (Lasso): 0.7605255539786694\n",
      "Lasso:\n",
      "  Train RMSE: $218125.63, Test RMSE: $224985.00\n",
      "  Train MAE: $139120.93, Test MAE: $144212.97\n",
      "  Train R^2: 0.43, Test R^2: 0.47\n",
      "Train RMSE: 218125.63\n",
      "Test RMSE: 224985.00\n",
      "Train MAE: 139120.93\n",
      "Test MAE: 144212.97\n",
      "Train R^2: 0.43\n",
      "Test R^2: 0.47\n"
     ]
    }
   ],
   "source": [
    "# Define the Lasso Regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "lasso_param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10]  # Regularization strength\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "lasso_grid_search = GridSearchCV(\n",
    "    estimator=lasso_model,\n",
    "    param_grid=lasso_param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "lasso_grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Best parameters and performance\n",
    "print(\"Best Parameters (Lasso):\", lasso_grid_search.best_params_)\n",
    "print(\"Best RMSE (Lasso):\", -lasso_grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the train and test sets\n",
    "best_lasso_model = lasso_grid_search.best_estimator_\n",
    "results_lasso = evaluate_model(best_lasso_model, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_target)\n",
    "\n",
    "# Display evaluation results\n",
    "for metric, value in results_lasso.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather evaluation metrics and compare to the previous step (full feature set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
