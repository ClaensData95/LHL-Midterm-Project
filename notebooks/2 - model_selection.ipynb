{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "This notebook should include preliminary and baseline modeling.\n",
    "- Try as many different models as possible.\n",
    "- Don't worry about hyperparameter tuning or cross validation here.\n",
    "- Ideas include:\n",
    "    - linear regression\n",
    "    - support vector machines\n",
    "    - random forest\n",
    "    - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "from functions_variables import evaluate_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "X_train = pd.read_csv('/home/t0si/LHL-Midterm-Project/notebooks/processed/X_train.csv')\n",
    "X_test = pd.read_csv('/home/t0si/LHL-Midterm-Project/notebooks/processed/X_test.csv')\n",
    "y_train = pd.read_csv('/home/t0si/LHL-Midterm-Project/notebooks/processed/y_train.csv').values\n",
    "y_test = pd.read_csv('/home/t0si/LHL-Midterm-Project/notebooks/processed/y_test.csv').values\n",
    "\n",
    "# Load the fitted scaler for the target variable\n",
    "scaler_target = joblib.load('scaler_target.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_target.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fit the scaler on the training target\n",
    "\n",
    "scaler_target = StandardScaler()\n",
    "y_train_scaled = scaler_target.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_scaled = scaler_target.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Save the fitted scaler for reuse\n",
    "import joblib\n",
    "joblib.dump(scaler_target, 'scaler_target.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t0si/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/t0si/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Train RMSE: $0.75, Test RMSE: $0.78\n",
      "  Train MAE: $0.48, Test MAE: $0.50\n",
      "  Train R^2: 0.43, Test R^2: 0.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t0si/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/t0si/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR:\n",
      "  Train RMSE: $0.45, Test RMSE: $0.53\n",
      "  Train MAE: $0.20, Test MAE: $0.25\n",
      "  Train R^2: 0.80, Test R^2: 0.76\n",
      "RandomForestRegressor:\n",
      "  Train RMSE: $0.06, Test RMSE: $0.11\n",
      "  Train MAE: $0.02, Test MAE: $0.04\n",
      "  Train R^2: 1.00, Test R^2: 0.99\n",
      "XGBRegressor:\n",
      "  Train RMSE: $0.04, Test RMSE: $0.11\n",
      "  Train MAE: $0.03, Test MAE: $0.04\n",
      "  Train R^2: 1.00, Test R^2: 0.99\n",
      "Evaluation Results:\n",
      "{'Linear Regression': {'Train RMSE': 0.7548294138434759, 'Test RMSE': 0.7815421807186136, 'Train MAE': 0.4827835786117934, 'Test MAE': 0.5025264577553163, 'Train R^2': 0.4302325559967145, 'Test R^2': 0.46815087548842516}, 'SVR': {'Train RMSE': 0.4488613347061851, 'Test RMSE': 0.53022693272083, 'Train MAE': 0.203190416304828, 'Test MAE': 0.25032574643785677, 'Train R^2': 0.798523502205782, 'Test R^2': 0.755202391015127}, 'Random Forest': {'Train RMSE': 0.05681536866568538, 'Test RMSE': 0.11244181091723067, 'Train MAE': 0.017274949424812943, 'Test MAE': 0.03805001119019502, 'Train R^2': 0.9967720138833822, 'Test R^2': 0.988991218122861}, 'XGBoost': {'Train RMSE': 0.04082686950168615, 'Test RMSE': 0.10734511253522713, 'Train MAE': 0.02755755784773773, 'Test MAE': 0.040713594807921076, 'Train R^2': 0.9983331667266923, 'Test R^2': 0.9899665993374759}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/t0si/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/t0si/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/t0si/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/home/t0si/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize models\n",
    "lr_model = LinearRegression()\n",
    "svr_model = SVR()\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "xgb_model = XGBRegressor(tree_method='hist', random_state=42)  # Force CPU execution\n",
    "\n",
    "\n",
    "xgb_model.fit(X_train, y_train.ravel())\n",
    "\n",
    "# Initialize results dictionary\n",
    "results = {}\n",
    "\n",
    "# Evaluate models\n",
    "results['Linear Regression'] = evaluate_model(lr_model, X_train, X_test, y_train, y_test, scaler_target)\n",
    "results['SVR'] = evaluate_model(svr_model, X_train, X_test, y_train, y_test, scaler_target)\n",
    "results['Random Forest'] = evaluate_model(rf_model, X_train, X_test, y_train, y_test, scaler_target)\n",
    "results['XGBoost'] = evaluate_model(xgb_model, X_train, X_test, y_train, y_test, scaler_target)\n",
    "\n",
    "# Display results\n",
    "print(\"Evaluation Results:\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Train RMSE  Test RMSE  Train MAE  Test MAE  Train R^2  \\\n",
      "Linear Regression    0.754829   0.781542   0.482784  0.502526   0.430233   \n",
      "SVR                  0.448861   0.530227   0.203190  0.250326   0.798524   \n",
      "Random Forest        0.056815   0.112442   0.017275  0.038050   0.996772   \n",
      "XGBoost              0.040827   0.107345   0.027558  0.040714   0.998333   \n",
      "\n",
      "                   Test R^2  \n",
      "Linear Regression  0.468151  \n",
      "SVR                0.755202  \n",
      "Random Forest      0.988991  \n",
      "XGBoost            0.989967  \n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame to store results\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what metrics you want to use to evaluate success.\n",
    "- If you think about mean squared error, can we actually relate to the amount of error?\n",
    "- Try root mean squared error so that error is closer to the original units (dollars)\n",
    "- What does RMSE do to outliers?\n",
    "- Is mean absolute error a good metric for this problem?\n",
    "- What about R^2? Adjusted R^2?\n",
    "- Briefly describe your reasons for picking the metrics you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather evaluation metrics and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - STRETCH\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its recommended you complete it if you have time!**\n",
    "\n",
    "Even with all the preprocessing we did in Notebook 1, you probably still have a lot of features. Are they all important for prediction?\n",
    "\n",
    "Investigate some feature selection algorithms (Lasso, RFE, Forward/Backward Selection)\n",
    "- Perform feature selection to get a reduced subset of your original features\n",
    "- Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?\n",
    "- Based on this, should you include feature selection in your final pipeline? Explain\n",
    "\n",
    "Remember, feature selection often doesn't directly improve performance, but if performance remains the same, a simpler model is often preferrable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform feature selection \n",
    "# refit models\n",
    "# gather evaluation metrics and compare to the previous step (full feature set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
