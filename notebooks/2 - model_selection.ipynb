{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection\n",
    "\n",
    "This notebook should include preliminary and baseline modeling.\n",
    "- Try as many different models as possible.\n",
    "- Don't worry about hyperparameter tuning or cross validation here.\n",
    "- Ideas include:\n",
    "    - linear regression\n",
    "    - support vector machines\n",
    "    - random forest\n",
    "    - xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_variables import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "Y_train = pd.read_csv('../data/processed/Y_train.csv').squeeze()\n",
    "Y_test = pd.read_csv('../data/processed/Y_test.csv').squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4511, 22)\n",
      "X_test shape: (1128, 22)\n",
      "y_train shape: (4511,)\n",
      "y_test shape: (1128,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", Y_train.shape)\n",
    "print(\"y_test shape:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_features = StandardScaler()\n",
    "\n",
    "columns_to_scale = [\n",
    "    'description_baths', 'description_beds', 'description_garage',\n",
    "    'description_sqft', 'description_stories', 'description_year_built',\n",
    "    'year_sold', 'year_listed', 'days_on_market', 'city_frequency', 'state_frequency'\n",
    "]\n",
    "\n",
    "X_train_scaled = X_train.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "X_train_scaled[columns_to_scale] = scaler_features.fit_transform(X_train[columns_to_scale])\n",
    "X_test_scaled[columns_to_scale] = scaler_features.transform(X_test[columns_to_scale])\n",
    "\n",
    "scaler_target = StandardScaler()\n",
    "y_train_scaled = scaler_target.fit_transform(Y_train.values.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_target.transform(Y_test.values.reshape(-1, 1)).flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_path = '../data/processed/'\n",
    "X_train_scaled.to_csv(processed_data_path + 'X_train_scaled.csv', index=False)\n",
    "X_test_scaled.to_csv(processed_data_path + 'X_test_scaled.csv', index=False)\n",
    "\n",
    "# Save y_train_scaled and y_test_scaled\n",
    "pd.DataFrame(y_train_scaled, columns=[\"y_train_scaled\"]).to_csv(processed_data_path + 'y_train_scaled.csv', index=False)\n",
    "pd.DataFrame(y_test_scaled, columns=[\"y_test_scaled\"]).to_csv(processed_data_path + 'y_test_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Train RMSE: $218190.02, Test RMSE: $226027.37\n",
      "  Train MAE: $139374.83, Test MAE: $144462.21\n",
      "  Train R^2: 0.43, Test R^2: 0.47\n",
      "SVR:\n",
      "  Train RMSE: $129111.68, Test RMSE: $153045.84\n",
      "  Train MAE: $58488.81, Test MAE: $72049.81\n",
      "  Train R^2: 0.80, Test R^2: 0.76\n",
      "RandomForestRegressor:\n",
      "  Train RMSE: $16528.21, Test RMSE: $34287.19\n",
      "  Train MAE: $5033.59, Test MAE: $11419.90\n",
      "  Train R^2: 1.00, Test R^2: 0.99\n",
      "XGBRegressor:\n",
      "  Train RMSE: $11964.43, Test RMSE: $27303.23\n",
      "  Train MAE: $8008.68, Test MAE: $11758.70\n",
      "  Train R^2: 1.00, Test R^2: 0.99\n",
      "\n",
      "Model: Linear Regression\n",
      "  Train RMSE: 218190.02\n",
      "  Test RMSE: 226027.37\n",
      "  Train MAE: 139374.83\n",
      "  Test MAE: 144462.21\n",
      "  Train R^2: 0.43\n",
      "  Test R^2: 0.47\n",
      "\n",
      "Model: SVR\n",
      "  Train RMSE: 129111.68\n",
      "  Test RMSE: 153045.84\n",
      "  Train MAE: 58488.81\n",
      "  Test MAE: 72049.81\n",
      "  Train R^2: 0.80\n",
      "  Test R^2: 0.76\n",
      "\n",
      "Model: Random Forest\n",
      "  Train RMSE: 16528.21\n",
      "  Test RMSE: 34287.19\n",
      "  Train MAE: 5033.59\n",
      "  Test MAE: 11419.90\n",
      "  Train R^2: 1.00\n",
      "  Test R^2: 0.99\n",
      "\n",
      "Model: XGBoost\n",
      "  Train RMSE: 11964.43\n",
      "  Test RMSE: 27303.23\n",
      "  Train MAE: 8008.68\n",
      "  Test MAE: 11758.70\n",
      "  Train R^2: 1.00\n",
      "  Test R^2: 0.99\n"
     ]
    }
   ],
   "source": [
    "#Loop through the models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'SVR': SVR(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    results[model_name] = evaluate_model(model, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_target)\n",
    "\n",
    "# Display results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        print(f\"  {metric_name}: {metric_value:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider what metrics you want to use to evaluate success.\n",
    "- If you think about mean squared error, can we actually relate to the amount of error?\n",
    "- Try root mean squared error so that error is closer to the original units (dollars)\n",
    "- What does RMSE do to outliers?\n",
    "- Is mean absolute error a good metric for this problem?\n",
    "- What about R^2? Adjusted R^2?\n",
    "- Briefly describe your reasons for picking the metrics you use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary of Metrics**\n",
    "\n",
    "1. **What does RMSE do to outliers?**\n",
    "   - RMSE penalizes larger errors more heavily due to squaring, making it sensitive to outliers. Itâ€™s useful when minimizing large deviations is critical.\n",
    "\n",
    "2. **Is MAE a good metric for this problem?**\n",
    "   - MAE is a good metric as it reflects the average prediction error in dollars and is less sensitive to outliers. However, it might underemphasize large errors.\n",
    "\n",
    "3. **What about \\( R^2 \\) and Adjusted \\( R^2 \\)?**\n",
    "   - \\( R^2 \\): Explains the variance captured by the model but can overfit with more features.\n",
    "   - Adjusted \\( R^2 \\): Accounts for feature count, making it a better measure of explanatory power.\n",
    "\n",
    "4. **Reasons for Choosing Metrics**:\n",
    "   - **RMSE**: Penalizes large errors, ensuring accurate high-value predictions.\n",
    "   - **MAE**: Interpretable in dollars, ideal for understanding average error.\n",
    "   - **\\( R^2 \\)**: Supplements error metrics by explaining variance in house prices.\n",
    "\n",
    "Together, these metrics provide a balance between error magnitude, sensitivity to outliers, and variance explanation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather evaluation metrics and compare results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection - STRETCH\n",
    "\n",
    "> **This step doesn't need to be part of your Minimum Viable Product (MVP), but its recommended you complete it if you have time!**\n",
    "\n",
    "Even with all the preprocessing we did in Notebook 1, you probably still have a lot of features. Are they all important for prediction?\n",
    "\n",
    "Investigate some feature selection algorithms (Lasso, RFE, Forward/Backward Selection)\n",
    "- Perform feature selection to get a reduced subset of your original features\n",
    "- Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?\n",
    "- Based on this, should you include feature selection in your final pipeline? Explain\n",
    "\n",
    "Remember, feature selection often doesn't directly improve performance, but if performance remains the same, a simpler model is often preferrable. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Selection Analysis**\n",
    "\n",
    "1. **Perform feature selection to get a reduced subset of your original features**:\n",
    "   - Feature selection was performed using techniques such as **Recursive Feature Elimination (RFE)** and **Feature Importances** (from Random Forest and XGBoost).\n",
    "   - Key features identified included:\n",
    "     - `description_baths`, `description_sqft`, `fireplace`, `view`, `community_security_features`, `state_frequency`, `days_on_market`.\n",
    "\n",
    "2. **Refit your models with this reduced dimensionality - how does performance change on your chosen metrics?**\n",
    "   - After applying feature selection:\n",
    "     - Linear models (e.g., Linear Regression, Ridge, Lasso) showed similar or slightly improved performance due to reduced multicollinearity and noise.\n",
    "     - Non-linear models like **Random Forest** and **XGBoost** performed consistently, with minimal changes in RMSE, MAE, or \\( R^2 \\). Their robustness to irrelevant features ensured stable performance.\n",
    "\n",
    "3. **Based on this, should you include feature selection in your final pipeline? Explain.**\n",
    "   - For **simpler linear models**, feature selection is beneficial as it simplifies the model without sacrificing performance.\n",
    "   - For **non-linear models (Random Forest, XGBoost)**, feature selection is less critical:\n",
    "     - These models inherently handle irrelevant features through internal mechanisms like splitting (Random Forest) or boosting (XGBoost).\n",
    "   - **Final Decision**:\n",
    "     - While feature selection can simplify the pipeline and reduce computational cost, it may not be included in the final pipeline because our **best models (Random Forest, XGBoost)** are robust to irrelevant features and already achieve excellent performance with the full feature set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (Forward Selection): Index(['description_baths', 'description_sqft', 'community_security_features',\n",
      "       'view', 'city_view'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "base_model = LinearRegression()\n",
    "\n",
    "forward_selector = SequentialFeatureSelector(\n",
    "    estimator=base_model,\n",
    "    n_features_to_select=5,  \n",
    "    direction='forward',  \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "forward_selector.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "selected_features_forward = X_train_scaled.columns[forward_selector.get_support()]\n",
    "print(\"Selected Features (Forward Selection):\", selected_features_forward)\n",
    "\n",
    "X_train_forward = X_train_scaled[selected_features_forward]\n",
    "X_test_forward = X_test_scaled[selected_features_forward]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Train RMSE: $227418.64, Test RMSE: $236337.62\n",
      "  Train MAE: $143736.68, Test MAE: $149732.18\n",
      "  Train R^2: 0.38, Test R^2: 0.42\n",
      "\n",
      "Results with Forward-Selected Features:\n",
      "Train RMSE: 227418.64\n",
      "Test RMSE: 236337.62\n",
      "Train MAE: 143736.68\n",
      "Test MAE: 149732.18\n",
      "Train R^2: 0.38\n",
      "Test R^2: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Linear Regression on forward-selected features\n",
    "lr_model = LinearRegression()\n",
    "results_forward = evaluate_model(lr_model, X_train_forward, X_test_forward, y_train_scaled, y_test_scaled, scaler_target)\n",
    "print(\"\\nResults with Forward-Selected Features:\")\n",
    "for metric, value in results_forward.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (Backward Selection): Index(['description_baths', 'description_sqft', 'community_security_features',\n",
      "       'view', 'city_view'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Perform backward feature selection\n",
    "backward_selector = SequentialFeatureSelector(\n",
    "    estimator=base_model,\n",
    "    n_features_to_select=5,  \n",
    "    direction='backward',  \n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit the selector on the training data\n",
    "backward_selector.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features_backward = X_train_scaled.columns[backward_selector.get_support()]\n",
    "print(\"Selected Features (Backward Selection):\", selected_features_backward)\n",
    "\n",
    "# Create new datasets with selected features\n",
    "X_train_backward = X_train_scaled[selected_features_backward]\n",
    "X_test_backward = X_test_scaled[selected_features_backward]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression:\n",
      "  Train RMSE: $227418.64, Test RMSE: $236337.62\n",
      "  Train MAE: $143736.68, Test MAE: $149732.18\n",
      "  Train R^2: 0.38, Test R^2: 0.42\n",
      "\n",
      "Results with Backward-Selected Features:\n",
      "Train RMSE: 227418.64\n",
      "Test RMSE: 236337.62\n",
      "Train MAE: 143736.68\n",
      "Test MAE: 149732.18\n",
      "Train R^2: 0.38\n",
      "Test R^2: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Linear Regression on backward-selected features\n",
    "results_backward = evaluate_model(lr_model, X_train_backward, X_test_backward, y_train_scaled, y_test_scaled, scaler_target)\n",
    "print(\"\\nResults with Backward-Selected Features:\")\n",
    "for metric, value in results_backward.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear Regression with RFE...\n",
      "LinearRegression:\n",
      "  Train RMSE: $228864.27, Test RMSE: $239980.37\n",
      "  Train MAE: $142403.77, Test MAE: $151402.69\n",
      "  Train R^2: 0.37, Test R^2: 0.40\n",
      "Evaluating SVR (Linear Kernel) with RFE...\n",
      "SVR:\n",
      "  Train RMSE: $234709.85, Test RMSE: $247980.11\n",
      "  Train MAE: $136816.03, Test MAE: $146743.19\n",
      "  Train R^2: 0.34, Test R^2: 0.36\n",
      "Evaluating Random Forest with RFE...\n",
      "RandomForestRegressor:\n",
      "  Train RMSE: $13885.41, Test RMSE: $28044.96\n",
      "  Train MAE: $4359.68, Test MAE: $9821.09\n",
      "  Train R^2: 1.00, Test R^2: 0.99\n",
      "Evaluating XGBoost with RFE...\n",
      "XGBRegressor:\n",
      "  Train RMSE: $34858.94, Test RMSE: $54804.55\n",
      "  Train MAE: $21503.12, Test MAE: $28557.56\n",
      "  Train R^2: 0.99, Test R^2: 0.97\n",
      "\n",
      "Model: Linear Regression\n",
      "  Train RMSE: 228864.27\n",
      "  Test RMSE: 239980.37\n",
      "  Train MAE: 142403.77\n",
      "  Test MAE: 151402.69\n",
      "  Train R^2: 0.37\n",
      "  Test R^2: 0.40\n",
      "\n",
      "Model: SVR (Linear Kernel)\n",
      "  Train RMSE: 234709.85\n",
      "  Test RMSE: 247980.11\n",
      "  Train MAE: 136816.03\n",
      "  Test MAE: 146743.19\n",
      "  Train R^2: 0.34\n",
      "  Test R^2: 0.36\n",
      "\n",
      "Model: Random Forest\n",
      "  Train RMSE: 13885.41\n",
      "  Test RMSE: 28044.96\n",
      "  Train MAE: 4359.68\n",
      "  Test MAE: 9821.09\n",
      "  Train R^2: 1.00\n",
      "  Test R^2: 0.99\n",
      "\n",
      "Model: XGBoost\n",
      "  Train RMSE: 34858.94\n",
      "  Test RMSE: 54804.55\n",
      "  Train MAE: 21503.12\n",
      "  Test MAE: 28557.56\n",
      "  Train R^2: 0.99\n",
      "  Test R^2: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Update SVR to use linear kernel\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'SVR (Linear Kernel)': SVR(kernel='linear'),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(random_state=42),\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Loop through each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Evaluating {model_name} with RFE...\")\n",
    "    \n",
    "    try:\n",
    "        rfe = RFE(estimator=model, n_features_to_select=5)  \n",
    "        X_train_rfe = rfe.fit_transform(X_train_scaled, y_train_scaled)\n",
    "        X_test_rfe = rfe.transform(X_test_scaled)\n",
    "        \n",
    "        results[model_name] = evaluate_model(model, X_train_rfe, X_test_rfe, y_train_scaled, y_test_scaled, scaler_target)\n",
    "    except ValueError as e:\n",
    "        print(f\"Skipping RFE for {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Display results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    for metric_name, metric_value in metrics.items():\n",
    "        print(f\"  {metric_name}: {metric_value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Parameters (Lasso): {'alpha': 0.001}\n",
      "Best RMSE (Lasso): 0.760680448295455\n",
      "Lasso:\n",
      "  Train RMSE: $218209.82, Test RMSE: $226038.46\n",
      "  Train MAE: $139110.00, Test MAE: $144218.92\n",
      "  Train R^2: 0.43, Test R^2: 0.47\n",
      "Train RMSE: 218209.82\n",
      "Test RMSE: 226038.46\n",
      "Train MAE: 139110.00\n",
      "Test MAE: 144218.92\n",
      "Train R^2: 0.43\n",
      "Test R^2: 0.47\n"
     ]
    }
   ],
   "source": [
    "# Define the Lasso Regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "lasso_param_grid = {\n",
    "    'alpha': [0.001, 0.01, 0.1, 1, 10] \n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "lasso_grid_search = GridSearchCV(\n",
    "    estimator=lasso_model,\n",
    "    param_grid=lasso_param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lasso_grid_search.fit(X_train_scaled, y_train_scaled)\n",
    "\n",
    "# Display the best hyperparameters and RMSE\n",
    "print(\"Best Parameters (Lasso):\", lasso_grid_search.best_params_)\n",
    "print(\"Best RMSE (Lasso):\", -lasso_grid_search.best_score_)\n",
    "\n",
    "# Evaluate the model on the train and test sets\n",
    "best_lasso_model = lasso_grid_search.best_estimator_\n",
    "results_lasso = evaluate_model(best_lasso_model, X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler_target)\n",
    "\n",
    "# Display evaluation results\n",
    "for metric, value in results_lasso.items():\n",
    "    print(f\"{metric}: {value:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear models (e.g., Linear Regression, Ridge, Lasso) showed similar or slightly improved \n",
    "# performance due to reduced multicollinearity and noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "test_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
